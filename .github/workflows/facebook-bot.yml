name: FB Gossip Bot (2 Hours)

on:
  push:
    paths:
      - '.github/workflows/fb-gossip.yml' # Runs immediately when you save
  schedule:
    # Runs at minute 10 of every 2nd hour (6:10 AM, 8:10 AM, etc.)
    - cron: '10 3,5,7,9,11,13,15,17,19,21 * * *'
  workflow_dispatch:

permissions:
  contents: write # CRITICAL for saving memory file

jobs:
  post-gossip-text:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install requests google-genai apify-client beautifulsoup4

      - name: Run Gossip Engine
        env:
          GEMINI_POOL: "${{ secrets.GEMINI_API_KEY }},${{ secrets.GEMINI_API_KEY1 }},${{ secrets.GEMINI_API_KEY2 }},${{ secrets.GEMINI_WRITE_KEY }}"
          APIFY_POOL: "${{ secrets.APIFY_API_TOKEN }},${{ secrets.APIFY_API_TOKEN1 }},${{ secrets.APIFY_API_TOKEN2 }},${{ secrets.APIFY_API_TOKEN3 }},${{ secrets.APIFY_API_TOKEN4 }},${{ secrets.APIFY_API_TOKEN5 }}"
          FB_TOKEN: ${{ secrets.FACEBOOK_PAGE_TOKEN }}
          MEMORY_FILE: .github/fb_gossip_memory.json
        run: |
          python << 'EOF'
          import os, json, requests, random, hashlib, re, sys
          from google import genai
          from apify_client import ApifyClient
          from bs4 import BeautifulSoup

          # 1. SETUP MEMORY
          mem_path = os.environ.get('MEMORY_FILE')
          if os.path.exists(mem_path):
              with open(mem_path, 'r') as f: memory = json.load(f)
          else:
              memory = []

          # 2. DISCOVERY (KenyaMoja)
          print("üîç Checking KenyaMoja Entertainment...")
          try:
              res = requests.get("https://www.kenyamoja.com/entertainment", headers={'User-Agent': 'Mozilla/5.0'}, timeout=15)
              items = BeautifulSoup(res.text, 'html.parser').select('li.news-item')
          except Exception as e:
              print(f"‚ùå Connection failed: {e}")
              sys.exit(1)

          # 3. SCRAPE (Apify)
          raw_story, final_hash = None, None
          apify_keys = [k.strip() for k in os.environ.get("APIFY_POOL", "").split(",") if k.strip()]
          apify = ApifyClient(random.choice(apify_keys))

          for item in items:
              link = item.select_one('.news-title a')
              if link:
                  url = link['href']
                  h = hashlib.md5(url.encode()).hexdigest()
                  if h not in memory:
                      print(f"üï∑Ô∏è Scraping: {url}")
                      try:
                          run = apify.actor("apify/website-content-crawler").call(run_input={"startUrls": [{"url": url}], "maxCrawlPages": 1})
                          data = list(apify.dataset(run["defaultDatasetId"]).iterate_items())
                          if data and len(data[0].get('markdown', '')) > 300:
                              raw_story = data[0]['markdown']
                              final_hash = h
                              break
                      except: continue
          
          if not raw_story:
              print("‚ö†Ô∏è No new content found. Exiting.")
              sys.exit(0)

          # 4. GENERATE (Gemini)
          print("ü§ñ Generating Tea...")
          gem_keys = [k.strip() for k in os.environ.get("GEMINI_POOL", "").split(",") if k.strip()]
          gemini = genai.Client(api_key=random.choice(gem_keys))
          
          prompt = f"""ACT AS A SAVAGE NAIROBI GOSSIP COLUMNIST.
          SOURCE: {raw_story[:8000]}
          TASK: Write a 150-word Facebook post.
          STYLE: 
          - HOOK: Start with a savage one-liner.
          - SLANG: Use 'Kanairo', 'Tea', 'Wueh'.
          - TONE: Cynical, gossipy, no filter.
          - NO AI SLOP: No 'tapestry', 'realm'.
          - END: A spicy question.
          TAGS: #TMReport #Buzz #Trending"""
          
          res = gemini.models.generate_content(model="gemini-3-flash-preview", contents=prompt)
          gossip_text = res.text.strip().replace("*", "").replace("#", "") # Clean basic formatting
          
          # 5. POST (Facebook Graph API)
          print("üöÄ Posting to Facebook...")
          fb_token = os.environ.get("FB_TOKEN")
          # Append hashtags manually to ensure they exist
          final_msg = f"{gossip_text}\n\n#TMReport #Buzz #Trending"
          
          resp = requests.post(
              "https://graph.facebook.com/v24.0/me/feed",
              data={"message": final_msg, "access_token": fb_token}
          )
          
          if resp.status_code == 200:
              print("‚úÖ Posted successfully!")
              memory.append(final_hash)
              with open(mem_path, 'w') as f: json.dump(memory[-50:], f)
          else:
              print(f"‚ùå Facebook Error: {resp.text}")
              sys.exit(1)
          EOF

      - name: Save Memory
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add .github/fb_gossip_memory.json
          # Pull latest changes before committing to avoid conflicts
          git pull origin main --rebase
          git commit -m "bot: updated gossip memory" || echo "No changes to commit"
          git push origin main