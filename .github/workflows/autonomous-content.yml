name: Human-Centric Content Publisher

on:
  schedule:
    - cron: '0 1 * * *'   # 4AM EAT (Tech/Innovation)
    - cron: '0 11 * * *'  # 2PM EAT (Social/Business)
  workflow_dispatch:

permissions:
  contents: write

env:
  POSTS_DIR: src/content/posts

jobs:
  generate-and-publish:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.PERSONAL_GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install requests

      - name: Generate Grounded Content
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          UNSPLASH_ACCESS_KEY: ${{ secrets.UNSPLASH_ACCESS_KEY }}
        run: |
          python << 'EOF'
          import os, json, datetime, requests, re, random

          # --- 1. LOCAL CONTEXT ENGINE (Kenya Feb 2026) ---
          local_events = [
              "The February 2026 NSSF upper limit increase to KSh 108,000 and its impact on take-home pay.",
              "The surge in Kenyan TikTok creators earning millions through brand collabs.",
              "Nairobi's status as the 'Silicon Savannah' and the rise of local AI startups.",
              "The trend of Gen Z Kenyans rediscovering local boxing through social media hype.",
              "New tax enforcement measures from KRA focusing on digital platform earnings."
          ]
          
          personas = [
              {"name": "The Nairobi Insider", "tone": "Punchy, street-smart, uses local business context, avoids corporate fluff."},
              {"name": "The Skeptical Economist", "tone": "Direct, data-driven, focuses on how global trends hit the Kenyan pocketbook."},
              {"name": "The Digital Trendsetter", "tone": "Fast-paced, focused on social media shifts and creator economy."}
          ]

          current_persona = random.choice(personas)
          current_event = random.choice(local_events)

          # --- 2. THE ANTI-ROBOT PROMPT ---
          spec_text = f"""
          Write a 1200-word article for jonathanmwaniki.co.ke.
          
          VOICE: You are {current_persona['name']}. Your tone is {current_persona['tone']}.
          
          CRITICAL INSTRUCTION: 
          - DO NOT use the words: "geopolitical", "landscape", "tapestry", "pivotal", "delve", "testament", or "unprecedented". 
          - If you feel the urge to use 'geopolitical', use 'regional reality' or 'on-the-ground shifts' instead.
          - Weave in this specific context: {current_event}
          
          STRUCTURE:
          - Start with a concrete observation (e.g., 'Walking through Upper Hill today...').
          - Use 4 main sections with ## Headers.
          - Keep sentences varied. Short for impact. Long for detail. No mid-sentence dashes (â€”).

          STRICT OUTPUT FORMAT:
          TITLE: [Insert Title]
          DESCRIPTION: [Insert 2-sentence summary]
          IMAGE_PROMPT: [Cinematic 5-word scene for Unsplash]
          CATEGORY: [Business/Technology/Social]
          BODY:
          [Content starts here]
          """

          # --- 3. CALL GEMINI ---
          api_key = os.environ.get("GEMINI_API_KEY")
          url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={api_key}"
          
          payload = {
              "contents": [{ "parts": [{ "text": spec_text }] }],
              "generationConfig": { "temperature": 0.85, "topP": 0.9 } 
          }

          try:
              resp = requests.post(url, json=payload, timeout=60)
              data = resp.json()
              full_text = data["candidates"][0]["content"]["parts"][0]["text"]
          except Exception as e:
              print(f"Error fetching content: {e}")
              exit(1)

          # --- 4. DATA PARSING ---
          parsed = {}
          lines = full_text.splitlines()
          for line in lines:
              if line.startswith("TITLE:"): parsed["TITLE"] = line.replace("TITLE:", "").strip()
              elif line.startswith("DESCRIPTION:"): parsed["DESCRIPTION"] = line.replace("DESCRIPTION:", "").strip()
              elif line.startswith("IMAGE_PROMPT:"): parsed["IMAGE_KEYWORD"] = line.replace("IMAGE_PROMPT:", "").strip()
              elif line.startswith("CATEGORY:"): parsed["CATEGORY"] = line.replace("CATEGORY:", "").strip()

          body_start = full_text.find("BODY:") + 5
          parsed["BODY"] = full_text[body_start:].strip()

          # --- 5. IMAGE SEARCH ---
          img_key = os.environ.get("UNSPLASH_ACCESS_KEY")
          img_url = "https://images.unsplash.com/photo-1523805009345-7448845a9e53" # Nairobi default
          if img_key:
              s_url = f"https://api.unsplash.com/search/photos?query={parsed.get('IMAGE_KEYWORD', 'Nairobi City')}&client_id={img_key}&per_page=1"
              s_res = requests.get(s_url).json()
              if s_res.get('results'):
                  img_url = s_res['results'][0]['urls']['regular']

          # --- 6. FILE ASSEMBLY ---
          slug = re.sub(r'[^a-z0-9-]', '-', parsed["TITLE"].lower()).strip('-')
          final_md = f"""---
          title: "{parsed['TITLE']}"
          description: "{parsed['DESCRIPTION']}"
          date: "{datetime.datetime.utcnow().strftime('%Y-%m-%d')}"
          author: "Jonathan Mwaniki"
          image: "{img_url}"
          category: "{parsed['CATEGORY']}"
          ---

          {parsed['BODY']}
          """
          
          out_path = f"{os.environ.get('POSTS_DIR')}/{slug}.md"
          os.makedirs(os.path.dirname(out_path), exist_ok=True)
          with open(out_path, "w") as f:
              f.write(final_md)
          print(f"Successfully birthed a human-sounding article: {slug}")
          EOF

      - name: Commit and Push
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "content: daily human-curated update"