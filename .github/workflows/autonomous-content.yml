name: Auto Newser

on:
  schedule:
    - cron: '0 0 * * *'   # 3AM EAT (Sports)
    - cron: '0 6 * * *'   # 9AM EAT (Tech)
    - cron: '0 11 * * *'  # 2PM EAT (Finance)
    - cron: '0 14 * * *'  # 5PM EAT (Sports)
    - cron: '0 18 * * *'  # 9PM EAT (Finance)
    - cron: '0 22 * * *'  # 1AM EAT (Tech)
  workflow_dispatch:
    inputs:
      manual_topic:
        description: 'Force a topic (sports, technology, business)'
        required: false
        default: ''

permissions:
  contents: write

env:
  DEFAULT_BRANCH: main
  POSTS_DIR: src/content/posts

jobs:
  generate-and-publish:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          ref: ${{ env.DEFAULT_BRANCH }}
          token: ${{ secrets.PERSONAL_GITHUB_TOKEN || secrets.GITHUB_TOKEN }}
          persist-credentials: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # We need the NEWEST SDK for Gemini 2.0/3.0 support
          pip install requests google-genai apify-client

      - name: Generate article with Gemini
        env:
          GEMINI_WRITE_KEY: ${{ secrets.GEMINI_WRITE_KEY }}
          APIFY_API_TOKEN: ${{ secrets.APIFY_API_TOKEN }}
          UNSPLASH_ACCESS_KEY: ${{ secrets.UNSPLASH_ACCESS_KEY }}
          MANUAL_TOPIC: ${{ inputs.manual_topic }}
          POSTS_DIR: src/content/posts
        run: |
          python << 'EOF'
          import os, json, datetime, requests, re, random, time, textwrap
          from google import genai
          from google.genai import types
          from apify_client import ApifyClient

          # --- 1. CONFIGURATION & TOPIC ---
          date_str = datetime.datetime.utcnow().date().strftime("%Y-%m-%d")
          current_hour_utc = datetime.datetime.utcnow().hour
          
          manual_input = os.environ.get('MANUAL_TOPIC', '').strip().lower()
          
          # Topic Schedule
          if manual_input in ['sports', 'technology', 'business', 'politics']:
              topic = manual_input
          else:
              if current_hour_utc == 0 or current_hour_utc == 14: topic = 'sports'
              elif current_hour_utc == 6 or current_hour_utc == 22: topic = 'technology'
              elif current_hour_utc == 18: topic = 'finance'
              else: topic = 'business'
          
          # 100% Kenyan Source Map
          url_map = {
              'technology': 'https://techweez.com/',
              'sports': 'https://www.mozzartsport.co.ke/',
              'business': 'https://www.standardmedia.co.ke/business',
              'finance': 'https://www.standardmedia.co.ke/business',
              'politics': 'https://www.kenyans.co.ke/news'
          }
          
          target_url = url_map.get(topic, 'https://www.kenyans.co.ke/news')
          print(f"ðŸŽ¯ Topic: {topic} | Target: {target_url}")

          # --- 2. FETCH CONTENT (APIFY) ---
          apify = ApifyClient(os.environ.get("APIFY_API_TOKEN"))
          crawl_text = ""
          
          print(f"ðŸ•·ï¸ Crawling {target_url}...")
          try:
              run_input = {
                  "startUrls": [{"url": target_url}],
                  "maxCrawlPages": 1, 
                  "crawlerType": "cheerio",
                  "removeElementsCssSelector": "nav, footer, script, style, .ad, .advertisement, .subscribe-widget"
              }
              run = apify.actor("apify/website-content-crawler").call(run_input=run_input)
              
              for item in apify.dataset(run["defaultDatasetId"]).iterate_items():
                  crawl_text += item.get('markdown', '')[:3000] 
          except Exception as e:
              print(f"âŒ Apify Error: {e}")
              exit(0)
          
          if not crawl_text:
              print("No content found via Apify.")
              exit(0)

          # --- 3. IMAGE HELPER ---
          def get_real_image(query):
              access_key = os.environ.get("UNSPLASH_ACCESS_KEY")
              fallback = f"https://image.pollinations.ai/prompt/minimalist-abstract-3d-render-of-{query.replace(' ', '-')}-no-humans?width=1200&height=630&nologo=true"
              
              if not access_key: return fallback
              
              url = f"https://api.unsplash.com/photos/random?query={query}&orientation=landscape&client_id={access_key}"
              try:
                  resp = requests.get(url, timeout=10)
                  if resp.status_code == 200:
                      return resp.json()['urls']['regular']
              except: pass
              return fallback

          # --- 4. PROMPT ---
          hooks = [
             "Straight reporting: What happened, when, where, who, why.",
             "Key facts first: Timeline of events.",
             "Source-led: What experts/officials said.",
             "Data-driven: Numbers and impacts."
          ]
          selected_hook = random.choice(hooks)

          cat_map = { 'sports':'Sports', 'technology':'Technology', 'business':'Business', 'politics': 'Politics', 'finance': 'Business' }
          display_category = cat_map.get(topic, 'General')

          prompt = f'''STRICT REPORTING MODE for jonathanmwaniki.co.ke.

          SOURCE DATA (CRAWLED FROM {target_url}):
          {crawl_text}

          TASK: Write a FACTUAL news article based on the most significant story above.
          - NO OPINIONS. NO HYPOTHESIS. NO HALLUCINATIONS.
          - Report in neutral, professional journalist tone.
          - Opening: {selected_hook}

          OUTPUT FORMAT (exact):
          TITLE: [News-style headline, 60 chars]
          DESCRIPTION: [Factual 1-2 sentence summary, 160 chars]
          CATEGORY: [{display_category}]
          TAGS: [3-5 relevant tags]
          IMAGE_KEYWORD: [2-3 words for image]
          BODY:
          [Full article: 1200-1600 words. ## Headers for sections. Cite sources inline.]

          RULES:
          - Facts only. If unknown, say "details unclear".
          - UK English, commas not em-dashes.
          - 5-7 sections: Background, Key Developments, Impacts, Reactions, Next Steps.'''

          # --- 5. GEMINI CALL (Updated SDK) ---
          client = genai.Client(api_key=os.environ.get("GEMINI_WRITE_KEY"))
          
          # UPDATED MODEL ID:
          # Try 'gemini-2.0-flash-exp' or 'gemini-1.5-pro' if available. 
          # 'gemini-1.5-flash' is the standard stable fast model.
          model_id = "gemini-2.0-flash-exp" 
          
          print(f"ðŸ¤– Generating with {model_id}...")
          
          try:
              response = client.models.generate_content(
                  model=model_id,
                  contents=prompt,
                  config=types.GenerateContentConfig(
                      temperature=0.1
                  )
              )
              full_text = response.text.strip()
          except Exception as e:
              print(f"âŒ Gemini Error: {e}")
              # Fallback to 1.5 Pro if 2.0 Flash is not yet rolled out to your key
              try:
                  print("âš ï¸ Retrying with gemini-1.5-pro...")
                  response = client.models.generate_content(
                      model="gemini-1.5-pro",
                      contents=prompt
                  )
                  full_text = response.text.strip()
              except Exception as e2:
                  print(f"âŒ Fatal Error: {e2}")
                  exit(1)

          # --- 6. PARSE ---
          parsed = { "TITLE": f"News {date_str}", "DESCRIPTION": "Latest updates", "CATEGORY": display_category, "TAGS": f"{topic},news", "IMAGE_KEYWORD": topic, "BODY": "" }
          
          lines = full_text.splitlines()
          body_started = False
          
          for line in lines:
              clean = line.strip().replace("**", "")
              if clean.startswith("TITLE:"): parsed["TITLE"] = clean.replace("TITLE:", "").strip()
              elif clean.startswith("DESCRIPTION:"): parsed["DESCRIPTION"] = clean.replace("DESCRIPTION:", "").strip()
              elif clean.startswith("CATEGORY:"): parsed["CATEGORY"] = clean.replace("CATEGORY:", "").strip()
              elif clean.startswith("TAGS:"): parsed["TAGS"] = clean.replace("TAGS:", "").strip()
              elif clean.startswith("IMAGE_KEYWORD:"): parsed["IMAGE_KEYWORD"] = clean.replace("IMAGE_KEYWORD:", "").strip()
              elif clean.startswith("BODY:"): body_started = True
              elif body_started: parsed["BODY"] += line + "\n"

          if not parsed["BODY"] and not body_started: parsed["BODY"] = full_text

          for key in ["TITLE", "DESCRIPTION", "BODY"]:
              parsed[key] = parsed[key].replace("â€”", ", ").replace("â€“", ", ").replace("--", ", ")

          # --- 7. SAVE ---
          image_url = get_real_image(parsed['IMAGE_KEYWORD'])
          slug = re.sub(r'[^a-z0-9-]', '-', parsed["TITLE"].lower())
          slug = re.sub(r'-+', '-', slug).strip('-')
          tag_list = [t.strip() for t in parsed["TAGS"].split(',')]

          final_file = f"""---
          title: "{parsed['TITLE'].replace('"', "'")}"
          description: "{parsed['DESCRIPTION'].replace('"', "'")}"
          date: "{date_str}"
          author: "Jonathan Mwaniki"
          image: "{image_url}"
          imageCaption: "Image for {parsed['IMAGE_KEYWORD']}"
          imageAlt: "{parsed['IMAGE_KEYWORD']}"
          category: "{parsed['CATEGORY']}"
          tags: {json.dumps(tag_list)}
          featured: true
          draft: false
          slug: "{slug}"
          ---

          {parsed['BODY']}

          <div class="article-meta">
            <p><strong>Published:</strong> {date_str}</p>
            <p><strong>Author:</strong> Jonathan Mwaniki</p>
            <p><strong>Source:</strong> Crawled from {target_url}</p>
          </div>
          """

          final_file = textwrap.dedent(final_file).strip()
          out_dir = os.environ.get("POSTS_DIR", "src/content/posts")
          os.makedirs(out_dir, exist_ok=True)
          with open(os.path.join(out_dir, f"{slug}.md"), "w", encoding="utf-8") as f:
              f.write(final_file)
          print(f"âœ… Published: {slug}.md")
          EOF

      - name: Commit and push article
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "content: publish ${{ github.run_id }}"
          branch: ${{ env.DEFAULT_BRANCH }}
          file_pattern: ${{ env.POSTS_DIR }}/*.md
          commit_user_name: "Content Bot"
          commit_user_email: "actions@github.com"
        env:
          GITHUB_TOKEN: ${{ secrets.PERSONAL_GITHUB_TOKEN || secrets.GITHUB_TOKEN }}