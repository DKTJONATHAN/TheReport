name: Autonomous Real-Time Publisher (Apify + Groq)

on:
  schedule:
    - cron: '0 1,6,10,15 * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  generate-and-publish:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install requests groq apify-client

      - name: Crawl and Generate
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          APIFY_API_TOKEN: ${{ secrets.APIFY_API_TOKEN }}
          POSTS_DIR: src/content/posts
        run: |
          python << 'EOF'
          import os, json, datetime, requests, re
          from groq import Groq
          from apify_client import ApifyClient

          # 1. SETUP
          now = datetime.datetime.utcnow()
          date_str = now.strftime('%Y-%m-%d')
          
          client = Groq(api_key=os.environ.get("GROQ_API_KEY"))
          apify = ApifyClient(token=os.environ.get("APIFY_API_TOKEN"))

          # 2. CRAWL KENYANS.CO.KE
          print("Crawling kenyans.co.ke for real-time heat...")
          run_input = {
              "startUrls": [{"url": "https://www.kenyans.co.ke/news"}],
              "maxCrawlPages": 2,
              "crawlerType": "cheerio"
          }
          
          try:
              run = apify.actor("apify/website-content-crawler").call(run_input=run_input)
              raw_data = ""
              for item in apify.dataset(run["defaultDatasetId"]).iterate_items():
                  raw_data += f"\nSTORY: {item.get('metadata', {}).get('title')}\nFACTS: {item.get('markdown', '')[:2500]}\n"
          except Exception as e:
              print(f"Crawler Failed: {e}")
              exit(1)

          # 3. JSON CONSTRAINED GENERATION
          # We force the model into JSON mode to protect the Title and Image.
          system_msg = """
          You are a senior Nairobi Investigative Journalist. 
          LANGUAGE: Posh Nairobi English heavily infused with Sheng. NEVER write in pure Swahili. 
          STYLE: Savage, unapologetic, name-names. Use phrases like 'Kimeumana', 'Vumbi tu', and 'Sema ukweli'.
          OUTPUT: Return ONLY a valid JSON object.
          """

          user_msg = f"""
          DATE: {date_str}
          CRAWL DATA: {raw_data}

          TASK: Create a 1500-word explosive article.
          - TITLE: Must be a competitive, high-SEO headline in English/Sheng.
          - IMAGE_KEYWORD: Specific cinematic prompt for Unsplash.
          - BODY: Long-form, detailed, and fearless. Call out the corruption/betrayal found in the facts.
          
          JSON SCHEMA: {{"title": "", "description": "", "image_keyword": "", "body": "", "tags": []}}
          """

          try:
              chat = client.chat.completions.create(
                  model="llama-3.3-70b-versatile",
                  messages=[{"role": "system", "content": system_msg}, {"role": "user", "content": user_msg}],
                  response_format={"type": "json_object"},
                  temperature=0.8
              )
              res = json.loads(chat.choices[0].message.content)
          except Exception as e:
              print(f"JSON Generation Failed: {e}")
              exit(1)

          # 4. FINAL HUMANIZER (Protects Metadata)
          # We only humanize the 'body' string, leaving the 'title' and 'image' untouched.
          humanizer_prompt = f"Take this article and inject raw Nairobi energy. Use sentence fragments and aggressive Sheng for emphasis. Keep the language primarily English. ARTICLE: {res['body']}"
          
          final_body = client.chat.completions.create(
              model="llama-3.3-70b-versatile",
              messages=[{"role": "user", "content": humanizer_prompt}],
              temperature=1.0
          ).choices[0].message.content

          # 5. ASSEMBLY
          slug = re.sub(r'[^a-z0-9-]', '-', res['title'].lower()).strip('-')
          
          # Fetch cinematic image keyword for meta
          img_key = res.get('image_keyword', 'Nairobi Skyline')

          final_md = f"""---
          title: "{res['title']}"
          description: "{res['description']}"
          date: "{date_str}"
          imageKeyword: "{img_key}"
          featured: true
          ---

          {final_body}

          ---
          *Verified Fact-check: Grounded via Kenyans.co.ke Real-time Crawl.*
          """

          os.makedirs(os.environ['POSTS_DIR'], exist_ok=True)
          with open(f"{os.environ['POSTS_DIR']}/{slug}.md", "w", encoding="utf-8") as f:
              f.write(final_md)
          EOF

      - name: Commit and Push
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "content: savage apify crawl update [${{ github.run_id }}]"