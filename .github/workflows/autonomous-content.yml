name: International News (Human Core & GEO)

on:
  schedule:
    - cron: '0 2 * * *'   # 5:00 AM EAT (Politics)
    - cron: '0 5 * * *'   # 8:00 AM EAT (Sports)
    - cron: '0 8 * * *'   # 11:00 AM EAT (Business)
    - cron: '0 11 * * *'  # 2:00 PM EAT (Tech)
    - cron: '0 14 * * *'  # 5:00 PM EAT (Sports)
    - cron: '0 18 * * *'  # 9:00 PM EAT (Entertainment)
  workflow_dispatch:
    inputs:
      manual_topic:
        description: 'Force a topic'
        required: false
        default: ''

permissions:
  contents: write

env:
  DEFAULT_BRANCH: main
  POSTS_DIR: src/content/posts
  MEMORY_FILE: .github/scrape_memory.json

jobs:
  generate-and-publish:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ env.DEFAULT_BRANCH }}
          token: ${{ secrets.PERSONAL_GITHUB_TOKEN || secrets.GITHUB_TOKEN }}
          persist-credentials: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests google-genai

      - name: Generate Content
        env:
          GEMINI_POOL: "${{ secrets.GEMINI_API_KEY }},${{ secrets.GEMINI_API_KEY1 }},${{ secrets.GEMINI_API_KEY2 }},${{ secrets.GEMINI_WRITE_KEY }}"
          NEWSAPI_KEY: ${{ secrets.NEWSAPI_KEY }}
          UNSPLASH_ACCESS_KEY: ${{ secrets.UNSPLASH_ACCESS_KEY }}
          MANUAL_TOPIC: ${{ github.event.inputs.manual_topic }}
          MEMORY_FILE: ${{ env.MEMORY_FILE }}
          CRON_SCHEDULE: ${{ github.event.schedule }}
        run: |
          python << 'EOF'
          import os, json, datetime, requests, re, random, hashlib, time
          from google import genai
          from google.genai import types
          import textwrap

          # --- 1. ROTATION & INTERNAL LINK HELPERS ---
          def get_clean_pool(v): 
              return [k.strip() for k in v.split(",") if k.strip()]
          
          gem_pool = get_clean_pool(os.environ.get("GEMINI_POOL", ""))

          def get_internal_context():
              posts_dir = os.environ.get("POSTS_DIR")
              if not os.path.exists(posts_dir): return ""
              files = [f for f in os.listdir(posts_dir) if f.endswith('.md')]
              if not files: return ""
              sample = random.sample(files, min(len(files), 3))
              context = "PAST ARTICLES FOR INTERNAL LINKING:\n"
              for f in sample:
                  try:
                      with open(os.path.join(posts_dir, f), 'r') as content:
                          txt = content.read()
                          title_match = re.search(r'title:\s*"(.*?)"', txt)
                          title = title_match.group(1) if title_match else f
                          context += f"- Title: {title} | Slug: /posts/{f.replace('.md', '')}\n"
                  except: continue
              return context

          def run_gemini(p):
              random.shuffle(gem_pool)
              for k in gem_pool:
                  try:
                      client = genai.Client(api_key=k)
                      return client.models.generate_content(
                          model="gemini-3-flash-preview", 
                          contents=p,
                          config=types.GenerateContentConfig(temperature=0.88, max_output_tokens=8192)
                      ).text.strip()
                  except Exception as e:
                      print(f"Key Failed: {e}"); continue
              return None

          # --- 2. DISCOVERY ---
          cron_map = {'0 2 * * *': 'politics', '0 5 * * *': 'sports', '0 8 * * *': 'business', '0 11 * * *': 'technology', '0 14 * * *': 'sports', '0 18 * * *': 'entertainment'}
          topic = os.environ.get('MANUAL_TOPIC', '').lower() or cron_map.get(os.environ.get('CRON_SCHEDULE', ''), 'politics')
          memory_path = os.environ.get('MEMORY_FILE')
          memory = json.load(open(memory_path)) if os.path.exists(memory_path) else []

          news_api = os.environ.get("NEWSAPI_KEY")
          news_url = f"https://newsapi.org/v2/everything?q={topic}&language=en&sortBy=publishedAt&apiKey={news_api}"
          articles = requests.get(news_url).json().get('articles', [])

          target_article, final_hash = None, None
          for a in articles:
              u = a.get('url', '')
              h = hashlib.md5(u.encode()).hexdigest()
              if h not in memory and len(a.get('description', '')) > 50:
                  target_article = a
                  final_hash = h
                  break

          if not target_article:
              print("No new content found."); exit(0)

          # --- 3. THE PROMPT (Added Caption Requirement) ---
          internal_linking_context = get_internal_context()
          prompt = f"""OPERATE AS HUMAN INTELLIGENCE DISGUISED AS CONVERSATION.
          Write a 1700-word investigative report.
          SOURCE TITLE: {target_article['title']}
          SOURCE SNIPPET: {target_article['content']}

          {internal_linking_context}

          STYLE GUIDE:
          - ANSWER-FIRST: Address the core hook in the first two paragraphs.
          - HUMAN RHYTHM: Vary sentence lengths, use blunt fragments.
          - INTERNAL LINKING: Mention one of the PAST ARTICLES naturally and link to its slug.
          - NO AI SLOP: Ban 'tapestry', 'delve', 'testament', 'vibrant', 'realm'.
          - NO CONCLUSION: Stop abruptly with a provocative cliffhanger.
          - CONTRARIAN TWIST: Frame this from the DIRECTLY OPPOSITE angle of mainstream news.

          STRICT: NO EM-DASHES. UK English. ## Headers only.

          OUTPUT FORMAT:
          TITLE: [headline]
          DESCRIPTION: [blunt sentence]
          IMAGE_CAPTION: [A short, cynical, 1-sentence human-toned caption for the header image related to this topic. Max 20 words.]
          CATEGORY: [{topic.title()}]
          TAGS: [3 tags]
          IMAGE_KEYWORD: [2 words]
          BODY: [Full article. No summary headers.]"""

          output = run_gemini(prompt)
          if not output: exit(1)

          # --- 4. PARSE & CLEAN (Added Caption Parsing) ---
          parsed = {"TITLE": "Report", "DESC": "", "IMG": topic, "CAPTION": "", "BODY": ""}
          cur = None
          for line in output.splitlines():
              if line.startswith("TITLE:"): parsed["TITLE"] = line.replace("TITLE:", "").strip()
              elif line.startswith("DESCRIPTION:"): parsed["DESC"] = line.replace("DESCRIPTION:", "").strip()
              elif line.startswith("IMAGE_CAPTION:"): parsed["CAPTION"] = line.replace("IMAGE_CAPTION:", "").strip()
              elif line.startswith("IMAGE_KEYWORD:"): parsed["IMG"] = line.replace("IMAGE_KEYWORD:", "").strip()
              elif line.startswith("BODY:"): cur = "BODY"
              elif cur == "BODY": parsed["BODY"] += line + "\n"

          for k in ["TITLE", "DESC", "BODY", "CAPTION"]:
              parsed[k] = parsed[k].replace("—", ", ").replace("–", ", ").replace("--", ", ")
              parsed[k] = re.sub(r'(?i)(In conclusion|To summarize|Summary|Conclusion),?.*', '', parsed[k])

          # --- 5. SCHEMA & SAVE (Added Caption to Frontmatter) ---
          date_now = datetime.datetime.utcnow().date().strftime('%Y-%m-%d')
          slug = re.sub(r'[^a-z0-9-]', '-', parsed["TITLE"].lower()).strip('-')
          u_key = os.environ.get("UNSPLASH_ACCESS_KEY")
          
          def get_img(q):
              try:
                  r = requests.get(f"https://api.unsplash.com/photos/random?query={q}&orientation=landscape&client_id={u_key}", timeout=10)
                  return r.json()['urls']['regular']
              except: return "https://images.unsplash.com/photo-1504711432869-efd597cdd042"
          
          img_url = get_img(parsed['IMG'])

          schema_json = {
              "@context": "https://schema.org",
              "@type": "AnalysisNewsArticle",
              "headline": parsed['TITLE'],
              "description": parsed['DESC'],
              "datePublished": date_now,
              "author": [{"@type": "Person", "name": "Jonathan Mwaniki", "url": "https://jonathanmwaniki.co.ke"}],
              "image": [img_url],
              "articleBody": parsed['BODY'][:500] + "..." 
          }

          # Added imageCaption to frontmatter block below
          final_md = textwrap.dedent(f"""---
          title: "{parsed['TITLE'].replace('"', "'")}"
          description: "{parsed['DESC'].replace('"', "'")}"
          date: "{date_now}"
          author: "Jonathan Mwaniki"
          image: "{img_url}"
          imageCaption: "{parsed['CAPTION'].replace('"', "'")}"
          category: "{topic.title()}"
          slug: "{slug}"
          ---

          # {parsed['TITLE']}

          {parsed['BODY'].strip()}

          <script type="application/ld+json">
          {json.dumps(schema_json, indent=2)}
          </script>
          """).strip()

          out_dir = os.environ.get("POSTS_DIR")
          os.makedirs(out_dir, exist_ok=True)
          with open(os.path.join(out_dir, f"{slug}.md"), "w", encoding="utf-8") as f: f.write(final_md)
          
          memory.append(final_hash)
          with open(memory_path, 'w') as f: json.dump(memory[-200:], f)
          EOF

      - name: Git Safety Pull
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add .
          git stash -u
          git fetch origin main
          git pull origin main --rebase
          git stash pop || echo "Nothing to pop"

      - name: Commit and push
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "content: human-core publish with captions"
          branch: ${{ env.DEFAULT_BRANCH }}
          file_pattern: 'src/content/posts/*.md .github/scrape_memory.json'